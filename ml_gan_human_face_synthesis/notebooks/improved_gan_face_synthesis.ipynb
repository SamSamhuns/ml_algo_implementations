{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved GAN face synthesis\n",
    "\n",
    "This will be an improvement over the previous implementation of our GAN with research-proven methods to improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "-   Adding noise to images used for training the GAN\n",
    "    -   Sønderby, Casper Kaae, Jose Caballero, Lucas Theis, Wenzhe Shi, and Ferenc Huszár. “Amortised MAP Inference for Image Super-Resolution.” ArXiv:1610.04490 [Cs, Stat], February 21, 2017. http://arxiv.org/abs/1610.04490.\n",
    "\n",
    "-   Use of DNNs in GAN, ADAM Optimizer for Generator and SGD for Discriminator\n",
    "\n",
    "    -   Radford, Alec, Luke Metz, and Soumith Chintala. “Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.” ArXiv:1511.06434 [Cs], January 7, 2016. http://arxiv.org/abs/1511.06434.\n",
    "    \n",
    "-   One sided label smoothing \n",
    "\n",
    "    -   Salimans, Tim, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. “Improved Techniques for Training GANs.” ArXiv:1606.03498 [Cs], June 10, 2016. http://arxiv.org/abs/1606.03498."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T13:52:01.697Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from PIL import Image\n",
    "from typing import Set\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T12:59:23.586742Z",
     "start_time": "2020-04-28T12:59:23.583948Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Device Configuration\n",
    "\n",
    "Check if GPU training is available with cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T12:59:23.611467Z",
     "start_time": "2020-04-28T12:59:23.587707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU training available\n",
      "Index of CUDA device in use is 0\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    # inbuilt cudnn auto-tuner searches for best algorithm for hardware\n",
    "    # cuddn.benchmark should be set to True when our input size does not vary\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"GPU training available\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"Index of CUDA device in use is {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(\"GPU training NOT available\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Can only train on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Object for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T12:59:23.616951Z",
     "start_time": "2020-04-28T12:59:23.612445Z"
    }
   },
   "outputs": [],
   "source": [
    "class HyperParameter():\n",
    "    def __init__(self,\n",
    "                 latent_sz,\n",
    "                 in_img_size,\n",
    "                 in_img_channel=3,\n",
    "                 data_dir=\"../data/img_align_celeba\",\n",
    "                 output_dir=\"../generated_imgs\",\n",
    "                 lr=0.0002,\n",
    "                 beta1=0.5,\n",
    "                 epochs=100,\n",
    "                 batch_sz=64,\n",
    "                 d_trained_wt_dir=\"../weights/discriminator_trained_weights\",\n",
    "                 g_trained_wt_dir=\"../weights/generator_trained_weights\"):\n",
    "        self.latent_size = latent_sz\n",
    "        self.learning_rate = lr\n",
    "        self.beta1 = beta1\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_sz\n",
    "        self.input_img_channel = in_img_channel\n",
    "        self.input_img_size = in_img_size\n",
    "\n",
    "        self.discriminator_trained_weight_dir = d_trained_wt_dir\n",
    "        self.generator_trained_weight_dir = g_trained_wt_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        os.makedirs(self.discriminator_trained_weight_dir, exist_ok=True)\n",
    "        os.makedirs(self.generator_trained_weight_dir, exist_ok=True)\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"latent_size: {self.latent_size}\\n\" + \\\n",
    "               f\"learning_rate: {self.learning_rate}\\n\" + \\\n",
    "               f\"beta1: {self.beta1}\\n\" + \\\n",
    "               f\"input_img_size: {self.input_img_size}\\n\" + \\\n",
    "               f\"input_img_channel: {self.input_img_channel}\\n\" + \\\n",
    "               f\"epochs: {self.epochs}\\n\" + \\\n",
    "               f\"batch_size: {self.batch_size}\\n\" + \\\n",
    "               f\"data_dir: {self.data_dir}\\n\" + \\\n",
    "               f\"output_dir: {self.output_dir}\\n\" + \\\n",
    "               f\"discriminator_trained_weight_dir: {self.discriminator_trained_weight_dir}\\n\" + \\\n",
    "               f\"generator_trained_weight_dir: {self.generator_trained_weight_dir}\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T12:59:23.623285Z",
     "start_time": "2020-04-28T12:59:23.617845Z"
    }
   },
   "outputs": [],
   "source": [
    "VALID_IMG_EXTENSIONS = {\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG', '.ppm', '.PPM', '.bmp',\n",
    "    '.BMP'\n",
    "}\n",
    "\n",
    "\n",
    "def _is_image_file(fpath, valid_img_ext: Set = VALID_IMG_EXTENSIONS) -> bool:\n",
    "    \"\"\"Validates if a file is an img file\"\"\"\n",
    "    _, img_ext = os.path.splitext(fpath)\n",
    "    return img_ext in valid_img_ext\n",
    "\n",
    "\n",
    "def make_img_dataset(root_dir, valid_img_ext: Set = VALID_IMG_EXTENSIONS):\n",
    "    \"\"\"Returns a list of valid img files after recursively chking in rootdir\"\"\"\n",
    "    img_dataset = []\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if _is_image_file(file, valid_img_ext):\n",
    "                img_path = os.path.join(subdir, file)\n",
    "                img_dataset.append(img_path)\n",
    "\n",
    "    return img_dataset\n",
    "\n",
    "\n",
    "def default_loader(img):\n",
    "    \"\"\"Converts img file into RGB mode\"\"\"\n",
    "    try:\n",
    "        opened_img = Image.open(img)\n",
    "        return opened_img.convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}. Skipping {img}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an ImageDataset Class that inherits from torch.utils.data.dataset.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T12:59:23.629399Z",
     "start_time": "2020-04-28T12:59:23.624178Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 root_dir,\n",
    "                 transform=None,\n",
    "                 valid_img_ext: Set = VALID_IMG_EXTENSIONS):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.face_dataset = make_img_dataset(root_dir, valid_img_ext)\n",
    "        if len(self.face_dataset) == 0:\n",
    "            raise IndexError(\"Face dataset is empty\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.face_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.face_dataset[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader class to get to iterate over the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T12:59:23.634278Z",
     "start_time": "2020-04-28T12:59:23.630643Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_loader(root_data_dir,\n",
    "                    data_transform=None,\n",
    "                    batch_size=64,\n",
    "                    num_workers=2,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True):\n",
    "    \"\"\"\n",
    "    root_dir is the directory with the images\n",
    "    \"\"\"\n",
    "    face_dataset = ImageDataset(root_data_dir, data_transform)\n",
    "    data_loader = torch.utils.data.DataLoader(face_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_workers=num_workers,\n",
    "                                              shuffle=shuffle,\n",
    "                                              drop_last=True)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "# Improved GAN implementation\n",
    "\n",
    "The Utility functions and the complement classes above are identical to our normal GAN implementation, but now we create Transform classes and the Generator-Discriminator Networks with enhanced structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing Transforms class where we add noise to input images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Noise Transform class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T12:59:23.640545Z",
     "start_time": "2020-04-28T12:59:23.635333Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        \"\"\" Gaussian Noise has a mu of 0 and sigma of 1\"\"\"\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T12:59:23.645336Z",
     "start_time": "2020-04-28T12:59:23.641439Z"
    }
   },
   "outputs": [],
   "source": [
    "img_data_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(160),\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "# Creating our Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Module\n",
    "\n",
    "With our base Discriminator Model, we were having problems with model collapse and the discriminator reducing its loss at a fast rate while the Generator Loss increased. This is usually due to the fact that our discriminator is learning too fast and has overfit the training data and the generator cannot learn anymore.\n",
    "\n",
    "So we add regularization to our Discriminator by adding `nn.Dropout(0.4)` layers after the activations which randonly zeros some of the elements of the input tensor with probability 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T13:24:58.340982Z",
     "start_time": "2020-04-28T13:24:51.698Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_img_size=64, in_img_channels=3, n_gpu=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.n_gpu = n_gpu\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # Input size is input_img_size*input_img_size*3 (img_width, img_height, input_img_channels)\n",
    "            nn.Linear(in_img_size * in_img_size * in_img_channels, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, X):\n",
    "        if X.is_cuda and self.n_gpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, X, range(self.n_gpu))\n",
    "        else:\n",
    "            output = self.main(X)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Module\n",
    "\n",
    "For our Generator Model, we avoid sparse gradients with layers of `ReLU` or `maxpooling`, instead we swtich to the `LeadkyReLU` activation in the Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T13:16:49.830237Z",
     "start_time": "2020-04-28T13:16:49.823267Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 latent_vector_size,\n",
    "                 in_img_size=64,\n",
    "                 in_img_channels=3,\n",
    "                 n_gpu=1):\n",
    "        super(Generator, self).__init__()\n",
    "        self.n_gpu = n_gpu\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # laten vector reprs the latent space\n",
    "            nn.Linear(latent_vector_size, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, in_img_size * in_img_size * in_img_channels),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, X):\n",
    "        if X.is_cuda and self.n_gpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, X, range(self.n_gpu))\n",
    "        else:\n",
    "            output = self.main(X)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Module\n",
    "\n",
    "We swtich the optimizer for the Discriminator Network to SGD from an ADAM optimizer.\n",
    "\n",
    "More importantly to penalize znd regularize the discriminator, we do one-sided smoothing with the Discriminator, i.e. if the label is real, then replace the label with a random number between 0.7 and 1.2\n",
    "\n",
    "We can also change some real_labels randomly to fake_labels when training the Discriminator to add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T13:42:39.514950Z",
     "start_time": "2020-04-28T13:42:39.495711Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    \"\"\"\n",
    "    GAN Class with fit method that trains the GAN\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 hyper_parameter,\n",
    "                 load_wt=True,\n",
    "                 save_wt=True,\n",
    "                 save_wt_interval=10,\n",
    "                 save_img_interval=50):\n",
    "        self.hp = hyper_parameter\n",
    "        self.G_net = Generator(self.hp.latent_size,\n",
    "                               self.hp.input_img_size).to(device)\n",
    "        self.D_net = Discriminator(self.hp.input_img_size).to(device)\n",
    "        self.D_loss_overtime = []\n",
    "        self.G_loss_overtime = []\n",
    "\n",
    "        if load_wt: self._load_saved_weights()\n",
    "        # Binary Cross Entropy Loss\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "        # Optimizers\n",
    "        self.G_optimizer = torch.optim.Adam(self.G_net.parameters(),\n",
    "                                            lr=self.hp.learning_rate,\n",
    "                                            betas=(self.hp.beta1, 0.999))\n",
    "        self.D_optimizer = torch.optim.Adam(self.D_net.parameters(),\n",
    "                                            lr=self.hp.learning_rate,\n",
    "                                            betas=(self.hp.beta1, 0.999))\n",
    "\n",
    "    def _load_saved_weights(self):\n",
    "        D_weight_files = glob(self.hp.discriminator_trained_weight_dir +\n",
    "                              '/*.pt')\n",
    "        if D_weight_files:\n",
    "            latest_D_wt = max(D_weight_files, key=os.path.getctime)\n",
    "            print(f\"Loading weight {latest_D_wt} for Discriminator\")\n",
    "            self.D_net.load_state_dict(torch.load(latest_D_wt))\n",
    "            self.D_net.eval()\n",
    "\n",
    "        G_weight_files = glob(self.hp.generator_trained_weight_dir + '/*.pt')\n",
    "        if G_weight_files:\n",
    "            latest_G_wt = max(G_weight_files, key=os.path.getctime)\n",
    "            print(f\"Loading weight {latest_G_wt} for Generator\")\n",
    "            self.G_net.load_state_dict(torch.load(latest_G_wt))\n",
    "            self.G_net.eval()\n",
    "\n",
    "    @staticmethod\n",
    "    def denorm(X):\n",
    "        \"\"\" This is the denorm when norm is done with transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\"\"\"\n",
    "        out = (X + 1) / 2\n",
    "        return out.clamp(0, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_gan_loss(G_loss, D_loss, save_dir=\"../loss_curves\"):\n",
    "        plt.plot(G_loss, label='Generator Loss')\n",
    "        plt.plot(D_loss, label='Discriminator Loss')\n",
    "        plt.title(\"GAN Loss\")\n",
    "        plt.ylabel(\"BCE Loss\")\n",
    "        plt.xlabel(\"Iterations (x10)\")\n",
    "        plt.legend()\n",
    "        \n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        plt.savefig(f\"{save_dir}/{time.time()}_GAN_loss.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_loss(self):\n",
    "        GAN.plot_gan_loss(self.G_loss_overtime, self.D_loss_overtime)\n",
    "\n",
    "    def fit(self, train_data_loader, save_wt=True, save_img_interval=50, save_wt_interval=10):\n",
    "        # Generator uses this noise to generate the images in the dataset for benchmarking\n",
    "        fixed_noise = torch.randn(self.hp.batch_size,\n",
    "                                  self.hp.latent_size,\n",
    "                                  device=device)\n",
    "\n",
    "        for epoch in tqdm(range(self.hp.epochs)):\n",
    "            d_running_loss, g_running_loss = 0, 0\n",
    "\n",
    "            # mini-batch training\n",
    "            for idx, data in enumerate(train_data_loader):\n",
    "                # # set to (64, -1) -1 should be equi to img_sz * img_sz * img_ch\n",
    "                X_data = data.reshape(self.hp.batch_size, -1)  \n",
    "                X_data = X_data.to(device)\n",
    "\n",
    "                # real_label = 1, fake_label = 0\n",
    "                # real_labels = torch.ones(self.hp.batch_size, 1).to(device) # FOR REFERENCE\n",
    "                real_labels = ((1.2-0.7)*torch.rand((self.hp.batch_size, 1)) + 0.7).to(device)\n",
    "                fake_labels = torch.zeros(self.hp.batch_size, 1).to(device)\n",
    "\n",
    "                ### Train Discriminator which maximizes log(D(x)) + log(1 - D(G(z))) ###\n",
    "                # Using real images\n",
    "                self.D_net.zero_grad()\n",
    "                D_real_output = self.D_net(X_data)  # feedforward\n",
    "                D_real_loss = self.criterion(D_real_output,\n",
    "                                             real_labels)  # cal loss\n",
    "                D_real_loss.backward()\n",
    "\n",
    "                # Using fake images\n",
    "                noise = torch.randn(self.hp.batch_size,\n",
    "                                    self.hp.latent_size,\n",
    "                                    device=device)\n",
    "                G_fake_output = self.G_net(noise)  # feedforward\n",
    "                D_fake_output = self.D_net(G_fake_output.detach())\n",
    "                D_fake_loss = self.criterion(D_fake_output, fake_labels)\n",
    "                D_fake_loss.backward()\n",
    "\n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "                self.D_optimizer.step()\n",
    "\n",
    "                ### Train Generator which maximizes log(D(G(z))) as Gradient Descent is expensive ###\n",
    "                self.G_net.zero_grad()\n",
    "                G_output = self.D_net(G_fake_output)\n",
    "                G_loss = self.criterion(G_output, real_labels)\n",
    "                G_loss.backward()\n",
    "                self.G_optimizer.step()\n",
    "\n",
    "                d_running_loss += D_loss.item()\n",
    "                g_running_loss += G_loss.item()\n",
    "                fmt_epoch = \"{:04d}\".format(epoch)\n",
    "                fmt_idx = \"{:04d}\".format(idx)\n",
    "\n",
    "                if idx % save_img_interval == 0:\n",
    "                    # Real image\n",
    "                    torchvision.utils.save_image(\n",
    "                        data,\n",
    "                        f'{self.hp.output_dir}/{fmt_epoch}_{fmt_idx}_real_samples.png',\n",
    "                        normalize=True)\n",
    "                    # Generated fake image\n",
    "                    fake_gen = self.G_net(fixed_noise)\n",
    "                    fake_gen = GAN.denorm(\n",
    "                        fake_gen.reshape(self.hp.batch_size, 3,\n",
    "                                         self.hp.input_img_size,\n",
    "                                         self.hp.input_img_size))\n",
    "                    torchvision.utils.save_image(\n",
    "                        fake_gen,\n",
    "                        f'{self.hp.output_dir}/{fmt_epoch}_{fmt_idx}_fake_samples.png',\n",
    "                        normalize=True)\n",
    "\n",
    "                if idx % 20 == 0:\n",
    "                    print(\n",
    "                        f\"Discriminator Loss at epoch: {epoch}, iter {idx} = {D_loss.item()}\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"Generator Loss at epoch: {epoch}, iter {idx} = {G_loss.item()}\"\n",
    "                    )\n",
    "\n",
    "                    d_avg_running_loss = d_running_loss / max(1, idx)\n",
    "                    g_avg_running_loss = g_running_loss / max(1, idx)\n",
    "                    self.D_loss_overtime.append(d_avg_running_loss)\n",
    "                    self.G_loss_overtime.append(g_avg_running_loss)\n",
    "\n",
    "                # Save checkpoint weights\n",
    "                if save_wt and idx % save_wt_interval == 0:\n",
    "                    torch.save(\n",
    "                        self.D_net.state_dict(),\n",
    "                        self.hp.discriminator_trained_weight_dir +\n",
    "                        f'/dnet_epoch_{fmt_epoch}_iter_{fmt_idx}.pt')\n",
    "                    torch.save(\n",
    "                        self.G_net.state_dict(),\n",
    "                        self.hp.generator_trained_weight_dir +\n",
    "                        f'/gnet_epoch_{fmt_epoch}_iter_{fmt_idx}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hyper-parameters, load data and apply transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T13:09:34.207005Z",
     "start_time": "2020-04-28T13:08:58.192848Z"
    }
   },
   "outputs": [],
   "source": [
    "hp = HyperParameter(latent_sz=100,\n",
    "                    in_img_size=64,\n",
    "                    in_img_channel=3,\n",
    "                    data_dir='../data/img_align_celeba/',\n",
    "                    output_dir=\"../improved_generated_imgs\",\n",
    "                    d_trained_wt_dir='../weights/improved_discriminator_trained_weights',\n",
    "                    g_trained_wt_dir='../weights/improved_generator_trained_weights',\n",
    "                    lr=0.0002,\n",
    "                    beta1=0.5,\n",
    "                    epochs=100,\n",
    "                    batch_sz=64)\n",
    "\n",
    "big_dataset = get_data_loader(hp.data_dir, data_transform=img_data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the GAN.fit() function to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T13:43:03.703Z"
    }
   },
   "outputs": [],
   "source": [
    "gan = GAN(hp)\n",
    "gan.fit(big_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.plot_loss()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
